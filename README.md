
# üìä An√°lise de Dados ‚Äì Projeto Olist E-commerce

## üë• Integrantes da Equipe

* **Caio Pal√°cio**
* *(Adicione outros integrantes aqui, se houver)*

---

## üîó Base de Dados Utilizada

**Fonte oficial:**
Olist E-commerce Public Dataset
Link: [https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

---

## üéØ Objetivo do Projeto

O objetivo deste projeto √© **analisar padr√µes de comportamento no e-commerce brasileiro**, identificando fatores que influenciam:

* satisfa√ß√£o do cliente,
* valor do frete,
* dimens√µes do produto,
* poss√≠veis causas de inconsist√™ncias nos dados.

A partir das an√°lises, buscou-se melhorar o entendimento do funcionamento geral do marketplace e levantar percep√ß√µes √∫teis para futuras aplica√ß√µes (modelagem estat√≠stica ou machine learning).

---

## üßπ Descri√ß√£o do Processo de Tratamento dos Dados

### 1. **Carregamento e inspe√ß√£o inicial**

Foram analisadas as colunas num√©ricas, categ√≥ricas e textuais, al√©m de verificada a exist√™ncia de valores nulos e duplicados.

### 2. **Remo√ß√£o de duplicatas**

Entradas duplicadas foram identificadas com `df.duplicated().sum()` e posteriormente removidas.

### 3. **Tratamento de valores ausentes (missing values)**

Linhas contendo valores nulos foram removidas para garantir consist√™ncia durante a an√°lise estat√≠stica e nos c√°lculos de correla√ß√£o.

### 4. **Tratamento de outliers**

Foi utilizada uma fun√ß√£o modificada baseada na mediana (m√©todo robusto), limitando valores extremos sem descart√°-los completamente.
Exemplo aplicado √†s colunas num√©ricas como `price`, `freight_value`, dimens√µes e peso do produto.

### 5. **Normaliza√ß√£o e padroniza√ß√£o**

Ap√≥s a limpeza, aplicou-se:

* **MinMaxScaler** ‚Üí normaliza√ß√£o 0‚Äì1
* **StandardScaler (Z-score)** ‚Üí padroniza√ß√£o baseada na m√©dia e desvio padr√£o

Os scalers foram aplicados tanto √†s colunas originais quanto √†s geradas por feature engineering.

### 6. **Feature Engineering**

Foram criadas novas vari√°veis para enriquecer a an√°lise, como:

* volume do produto (`product_length_cm * product_height_cm * product_width_cm`)
* densidade estimada
* rela√ß√µes entre pre√ßo, peso e frete
  Essas vari√°veis foram normalizadas e analisadas junto √†s demais.

### 7. **Correla√ß√£o**

Gerou-se um mapa de calor (heatmap) com **todas as colunas num√©ricas**, incluindo as derivadas, para avaliar poss√≠veis rela√ß√µes entre atributos.

---

## üßó Principais Desafios Encontrados

1. **Grande quantidade de outliers**
   Valores extremamente altos nas colunas de pre√ßo, frete e dimens√µes exigiram t√©cnicas robustas de suaviza√ß√£o.

2. **Variabilidade alta entre atributos**
   A diferen√ßa de escalas (cent√≠metros vs. reais vs. pesos) demandou normaliza√ß√£o adequada para permitir an√°lises compar√°veis.

3. **Dados inconsistentes e incompletos**
   Registros faltantes e duplicados impactavam estat√≠sticas e precisaram ser removidos com cuidado.

4. **Feature engineering sem causar vi√©s**
   Criar novas vari√°veis que fossem realmente informativas, sem redund√¢ncia ou distor√ß√µes, exigiu diversas itera√ß√µes.

---

## üí° Principais Conclus√µes

* Os dados apresentavam **outliers significativos**, especialmente relacionados a pre√ßo, frete e dimens√µes. Ap√≥s o tratamento, a distribui√ß√£o tornou-se mais est√°vel e adequada para an√°lise estat√≠stica.
* As colunas relacionadas ao **tamanho e peso do produto** mostraram correla√ß√£o moderada com o **valor do frete**, indicando impacto direto da log√≠stica sobre o custo.
* O processo de padroniza√ß√£o permitiu identificar padr√µes que n√£o eram vis√≠veis antes da normaliza√ß√£o.
* A engenharia de atributos (principalmente volume e densidade) trouxe informa√ß√µes complementares que ajudaram a explicar varia√ß√µes no pre√ßo e no frete.
* A limpeza dos dados alterou significativamente o comportamento das distribui√ß√µes, reduzindo assimetria e aumentando a confiabilidade das conclus√µes.

---
